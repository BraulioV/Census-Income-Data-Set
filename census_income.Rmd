---
title: "Analizando el dataset Census Income"
author: "Marta Gómez y Braulio Vargas"
date: "3 de junio de 2016"
lang: es
output: 
  pdf_document:
    fig_caption: yes
    includes:
      in_header: structure.tex
    number_sections: yes
    toc: yes
    highlight: pygments
bibliography: bibliografia.bib
csl: ieee-with-url.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	cache = TRUE
)
```

# Definición del problema a resolver y enfoque elegido

## Definición del problema

La base de datos escogida se denomina _Census Income_, aunque también es conocida como _Adult_ [@Lichman:2013]. Se puede descargar [aquí](http://archive.ics.uci.edu/ml/datasets/Census+Income "aqui"). Esta base de datos tiene 48842 instancias, cada una con 14 atributos. El problema es que también tiene valores perdidos.

El problema consiste en predecir cuando una persona va a gastarse más de $50K basándonos en los datos del censo. Por tanto, estamos ante un problema de _clasificación_.

Los atributos de los que disponemos son:

* ___age___: atributo numérico que expresa la edad de la persona.

* ___workclass___: atributo categórico que expresa el tipo de empleo que tiene la persona. Los valores que puede tomar son:

    * _Private_: persona contratada en una empresa privada.
    
    * _Self-emp-not-inc_: autónomo.
    
    * _Self-emp-inc_: persona que tiene una empresa grande.
    
    * _Federal-gov_: funcionario del gobierno federal.
    
    * _Local-gov_: funcionario del gobierno local.
    
    * _State-gov_: funcionario del gobierto estatal.
    
    * _Without-pay_: persona en paro.
    
    * _Never-worked_: persona que nunca ha trabajado.
    
* ___fnlwgt (final weight)___: variable numérica que representa un peso, cada peso corresponde a una característica socio-económica de la población, por tanto, personas con características demográficas parecidas deben tener un peso parecido. [@fnlwgt]

* ___education___: variable categórica que representa el nivel de estudios de la persona. Los valores que puede tomar son: _Bachelors_, _Some-college_, _11th_, _HS-grad_, _Prof-school_, _Assoc-acdm_, _Assoc-voc_, _9th_, _7th-8th_, _12th_, _Masters_, _1st-4th_, _10th_, _Doctorate_, _5th-6th_, _Preschool_.

* ___education-num___: variable númerica que representa a la anterior.

* ___marital-status___: variable categórica que expresa el estado sentimental de la persona. Los valores que puede tomar son: 

    * _Married-civ-spouse_: la persona está casada con un civil.
    
    * _Divorced_: la persona está divorciada.
    
    * _Never-married_: la persona nunca ha estado casada.
    
    * _Separated_: la persona está separada.
    
    * _Widowed_: la persona es viuda.
    
    * _Married-spouse-absent_: la persona aparece como casada en el registro, pero no se encuentra a ninguna pareja [@maritalstatus].
    
    * _Married-AF-spouse_: la persona está casada con alguien de las fuerzas armadas.
    
* ___occupation___: variable categórica que describe el tipo de profesión que tiene la persona. Puede tomar los valores _Tech-support_, _Craft-repair_, _Other-service_, _Sales_, _Exec-managerial_, _Prof-specialty_, _Handlers-cleaners_, _Machine-op-inspct_, _Adm-clerical_, _Farming-fishing_, _Transport-moving_, _Priv-house-serv_, _Protective-serv_, _Armed-Forces_. 

* ___relationship___: variable que contiene el valor que puede tomar la relación de una persona con respecto a otra dentro de una familia. Contiene solo un valor por instancia del dato. Estos valores pueden ser _Wife_ (Esposa), _Own-child_ (hijo propio), _Husband_ (marido), _Not-in-family_ (sin familia), _Other-relative_ (otro tipo de familiar) y _Unmarried_ (soltero).

* ___race___: valor que describe la raza de la persona. Puede ser _White_ (Blanco), _Asian-Pac-Islander_ (asíatico o de las islas del pacífico), _Amer-Indian-Eskimo_ (indio americano o esquimal), _Other_ (otro) y _Black_ (negro).

* ___sex___: sexo de la persona, _Female_ (mujer) o _Male_ (hombre).

* ___capital-gain___: registro de la ganancia de capital de la persona.

* ___capital-loss___: registro de la pérdida de capital de la persona.

* ___hours-per-week___: corresponde a las horas de trabajo a la semana.

* ___country___: país de pertenencia. En este caso, hay una mayor variedad de valores, siendo los siguientes: _United-States_, _Cambodia_, _England_, _Puerto-Rico_, _Canada_, _Germany_, _Outlying-US(Guam-USVI-etc)_, _India_, _Japan_, _Greece_, _South_, _China_, _Cuba_, _Iran_, _Honduras_, _Philippines_, _Italy_, _Poland_, _Jamaica_, _Vietnam_, _Mexico_, _Portugal_, _Ireland_, _France_, _Dominican-Republic_, _Laos_, _Ecuador_, _Taiwan_, _Haiti_, _Columbia_, _Hungary_, _Guatemala_, _Nicaragua_, _Scotland_, _Thailand_, _Yugoslavia_, _El-Salvador_, _Trinadad&Tobago_, _Peru_, _Hong_, _Holand-Netherlands_,  o lo que es lo mismo, Estados-Unidos, Colombia, Inglaterra, Puerto-Rico, Canada, Alemania, Estados supervisados de los Estados Unidos, India, Japón, Grecia, Sudáfrica, China, Cuba, Irán, Honduras, Filipinas, Italia, Polonia, Jamaica, Vietnam, México, Portugal, Irlanda, Francia, República Dominicana, Laos, Ecuador, Taiwn, Haití, Colombia, Hungría, Guatemala, Nicaragua, Escocia, Tailandia, Yugoslavia, El Salvador y Trinidad-Tobago.

* ___income___: corresponde al valor que queremos predecir, puede tomar los valores "<=50K" o ">50K"

## Enfoque elegido

El enfoque que usaremos para predecir la variable *income* es realizar tres modelos diferentes, cada uno con sus ventajas y desventajas, siendo uno un modelo ___paramétrico___, un modelo ___de base radial___ y un modelo basado en una ___red neuronal multicapa___. En el caso del modelo parámetrico, usaremos un modelo __Random Forest__, ya que obtiene un modelo que se ajusta muy bien a los datos, y además, `R` proporciona mecanismos para poder ajustar los parámetros óptimos y así no tener sobreajuste.

# Codificación de los datos de entrada para hacerlos útiles a los algoritmos

## Valores perdidos

Respecto a los valores perdidos, podríamos tomar tres enfoques diferentes: sustituirlos por una media, eliminar todas las filas que contengan algún valor perdido o no usar las variables que contengan valores perdidos. Para tomar esta decisión, primero hemos de estudiar el porcentaje de valores perdidos que presentan los datos.

Para ello, en primer lugar leemos los datos. 

```{r}
leer_datos <- function(fichero = "./Data/adult.data") {
    adult.train <- read.csv(fichero, header=FALSE, col.names = c("age","workclass", 
            "fnlwgt","education","education-num","marital-status","occupation","relationship",
            "race","sex","capital-gain","capital-loss","hours-per-week","country","income"), 
            na.strings = c(" ?", "?", ""), stringsAsFactors = F)
}

adult.train <- leer_datos()
adult.test <- leer_datos(fichero = "./Data/adult.test")
```

Para evitar problemas con las funciones de $R$, forzaremos a que todos los datos categóricos, tenga el mismo $factor$. Para ello, realizaremos lo siguiente:

```{r}
# Añadimos una columna a los datos para indicar 
# cuales pertenecen a datos de train y cuales a
# datos de test

adult.test$trainTest = rep(1,nrow(adult.test))
adult.train$trainTest = rep(0,nrow(adult.train))

# Reconstruimos el conjunto de datos al completo,
# uniendo los datos de train y test

fullSet <- rbind(adult.test,adult.train)

# Cada una de las variables categóricas, pasarán 
# de ser cadenas de caracteres a tener un valor 
# numérico o un factor, con lo que 
# tanto datos de train como datos de test, 
# obtendrán el mismo factor

fullSet$workclass = as.factor(fullSet$workclass)
fullSet$country = as.factor(fullSet$country)
fullSet$education = as.factor(fullSet$education)
fullSet$marital.status = as.factor(fullSet$marital.status)
fullSet$sex = as.factor(fullSet$sex)
fullSet$relationship = as.factor(fullSet$relationship)
fullSet$occupation = as.factor(fullSet$occupation)
fullSet$income = as.factor(fullSet$income)
fullSet$race = as.factor(fullSet$race)

# Reconstruimos los datos de train y test originales

adult.train = data.frame(fullSet[fullSet$trainTest == 0,])
adult.test = data.frame(fullSet[fullSet$trainTest == 1,])

# Y eliminamos la columna auxiliar

adult.test$trainTest = NULL
adult.train$trainTest = NULL
```


Una vez leídos, calculamos el número de variables perdidas en cada columna:

```{r}
apply(X=adult.train, MARGIN=2, FUN=function(columna) length(is.na(columna)[is.na(columna)==T]))
```

Sólo tienen valores perdidos los atributos _workclass_, _occupation_ y _country_.

También, vamos a comprobar el número de instancias que contienen algún dato perdido. Como ya hemos visto que los datos perdidos sólo se encuentran en las columnas *workclass*, *occupation* y *country*, nos fijaremos sólo en esas. Para ello, vamos a realizar lo siguiente:

```{r}
get_rows_na <- function(datos = adult.train) {
    aux = is.na(datos)*1
    rowsMissingValues = apply(X=aux, MARGIN=1,
             FUN = function(fila) sum(fila))
}

rowsMissingValues.train = get_rows_na()
length(rowsMissingValues.train[rowsMissingValues.train > 0])
```

En total, sólo hay 2399 filas con valores perdidos. Al tener en total 32561 datos de entrenamiento, perder 2399 no supone una gran diferencia. Por tanto, lo más sencillo es eliminar las filas que contengan algún dato perdido. Este mismo planteamiento es usado con los datos de test, donde tenemos 16282 filas en total, de las cuales 1222 presentan datos perdidos.

```{r}
adult.train.clean = adult.train[rowsMissingValues.train == 0,]
adult.test.clean = adult.test[get_rows_na(datos = adult.test) == 0,]
```

## Asignación de valores numéricos a los valores categóricos

Al cargar el fichero de datos hemos usado la opción `stringsAsFactors`. Esta función sirve para convertir todas las cadenas de carácteres en factores. Los factores, tal y como se explica en [@factores], asignan a cada posible valor que puede tomar una variable categórica un número. Los factores representan una forma de almacenamiento muy eficiente, ya que las cadenas de carácteres correspondientes sólo se almacenan una vez y los valores se guardan como enteros.

Por ejemplo, los números asociados a la variable `workclass` corresponden con el orden mostrado por la función `levels`. Así, al primer elemento se le asigna el número uno, al siguiente el dos, etc.

```{r}
levels(adult.train.clean$workclass)
```

Para ver el vector numérico almacenado por `R` en vez de el vector con las cadenas de caracteres usamos la función `c`:

```{r}
head(c(adult.train.clean$workclass))
head(adult.train.clean$workclass)
```

Como vemos, los números asignados a los primeros elementos coinciden con el orden mostrado anteriormente.

## Eliminando la variable `education.num`

Aunque cada problema tenga su propio método para escoger y normalizar variables, hemos considerado que la variable `education.num` no nos va a servir, ya que es únicamente una asignación numérica de los valores categóricos de la variable `education`. Al haber almacenado la variable `education` como factor, ya tiene una asignación numérica hecha, y por tanto, eliminamos la variable `education.num`:

```{r}
adult.train.clean[,"education.num"] = NULL
adult.test.clean[,"education.num"] = NULL
```

# Ajustando un modelo _Random Forest_

## Idoneidad del modelo *Random Forest* para los datos del problema

Como modelo paramétrico, el árbol es capaz de clasificar los datos con cierta precisión y tiene la ventaja de que por sí solo, es capaz de explicar bastante bien la clasificación que ha hecho. Pero, utilizar un sólo árbol no ofrece la potencia necesaria para ajustarse lo suficientemente bien a los datos, además de que sufre de tener una alta variabilidad, ya que si particionamos los datos aleatoriamente en subconjuntos, podemos obtener resultados muy diferentes si aprendemos el modelo con un subconjunto u otro, y por ello usaremos el modelo *Random Forest*, que aunque pierda las facilidades de comprensión que tiene un árbol, nos ofrece un poder de ajuste muchísimo mayor, y un poder de generalización mayor.

El porqué de usar *Random Forest* frente a un modelo *Bagging* es que con este último, tenemos que aprender el modelo usando las $p$ variables predictoras, mientras que con *Random Forest* podemos usar un subconjunto de tamaño $m$. *Bagging*, al hacer uso de los $p$ predictores, en el caso de que haya una variable predictora muy fuerte en los datos, todos los árboles que se acaben generando, tendrán esta variable predictora en los primeros nodos del árbol, mientras que al usar varios subconjuntos de los $p$ predictores de tamaño $m$ escogidos de forma aleatoria en *Random Forest*, seremos capaces de detectar otras relaciones más débiles entre las variables predictoras pero que también son capaces de predecir los datos con exactitud.

Respecto a los datos que tenemos (30162 datos de entrenamiento y 15060 datos de test)\footnote{Eliminando las instancias con valores perdidos.} tenemos suficientes datos como para que *Random Forest* trabaje de forma adecuada, y disponemos de 14 datos predictores, ya que la variable `income` es aquella que queremos predecir.

## Aplicación del modelo *Random Forest*

Para ajustar un modelo *Random Forest*, haremos uso del paquete *randomForest* de *R*. 

En primer lugar, vamos a ajustar un modelo _Random Forest_ con el número de predictores por defecto de `R`: $m = \sqrt{p}$. Siendo $p$ el número de variables predictoras totales. Este número por defecto es el recomendado para problemas de clasificación como éste. En este caso, al tener $p = 13$, el número de predictores a usar será $m = 3$.

```{r}
library(randomForest)

rf.clean = randomForest(income ~ ., data = adult.train.clean, importance = T)
print(rf.clean)
```

Con $m = 3$ obtenemos un modelo con un $18,18$% de error _Out-Of-Bag_. Al ajustar el modelo de Random Forest, cada uno de los árboles usa un subconjunto de los datos, y los no usados para calcular dicho árbol se quedan como _out of bag_. Una vez generados los árboles, se predice el valor de cada dato usando los árboles en los que dicho dato ha sido _out of bag_. En el caso de clasificación se hace mediante voto mayoritario. El error de clasificación obtenido para cada dato es válido, porque para predecir el dato se han usado árboles en los que el dato en cuestión no "ha participado" [@islroob].

Respecto a la matriz de confusión generada, vemos que hay muchos más aciertos para la clase `<=50K` que para la clase `>50K`. Esto puede deberse a que el número de instancias para el la clase `<=50K` sea mucho mayor y, por tanto, el modelo tienda a clasificar los datos como `<=50K`:

```{r}
length(adult.train.clean$income[adult.train.clean$income == "<=50K"])
length(adult.train.clean$income[adult.train.clean$income == ">50K"])
```

Como hemos dicho antes, hay una gran diferencia entre la proporción de datos para un clase y otra, esto hace que el modelo tienda a clasificar los datos como `<=50K`. De hecho, si nos fijamos en la matriz de confusión, los fallos de clasificación con `<=50K` son mucho mayores a los de `>50K`: 5442 frente a 51.

Ahora bien, ¿podemos llegar a obtener un error más bajo cambiando éste parámetro? Para ello, usamos la función `tuneRF`, que empieza en el valor por defecto de `R` y, a partir de éste, prueba con otros valores hasta encontrar el óptimo. En cada iteración, incrementa o decrementa el valor de $m$ según un parámetro `stepFactor` y además, si la mejora de error obtenida no es mayor a lo indicado por el parámetro `improve`, se para la búsqueda.

```{r}
rf.tuned = tuneRF(x=subset(adult.train.clean, select=-income), y=adult.train.clean$income, doBest=T)
```

Como vemos en la gráfica, con $m=3$ obtenemos el modelo óptimo. Por tanto, nos quedamos con el modelo generado anteriormente.

Lo último que podemos preguntarnos es, ¿cómo se comporta el modelo con los datos de test? Para saberlo, generamos la tabla de confusión:

```{r}
ypred = predict(rf.clean, adult.test.clean)
print(table(predict=ypred, truth=(adult.test.clean$income)))
```

De los 15060 datos de test que teníamos en total, el modelo ha acertado 123313 y ha fallado 2747. Al igual que en los datos de entrenamiento, se ve una mayoría de datos con clase `<=50K`. Aunque a la hora de los errores, ha habido más errores clasificando instancias `<=50K`: 34 frente a 2713.

```{r}
length(adult.test.clean$income[adult.test.clean$income == "<=50K"])
length(adult.test.clean$income[adult.test.clean$income == ">50K"])
```

Al haber esta diferencia en los datos de entrenamiento y test, los modelos obtenidos se ven muy afectados.

<!-- # Normalización de las variables -->

<!-- # Selección de las técnicas y valoración de la idoneidad de las mismas frente a otras alternativas -->

<!-- # Aplicación de la técnica -->

<!-- ## Estimación de los parámetros -->

<!-- ## Estimación de los hiperparámetros -->

<!-- ## Error de generalización -->

<!-- # Idoneidad de la función de regularización usada -->

<!-- # Valoración de resultados -->

<!-- # Justificación de la solución obtenida en base a la ténica usada y los datos. -->

<!-- ## Dimensión VC del modelo -->

<!-- ## Error de generalización del modelo -->

<!-- ## Curva de aprendizaje del modelo -->

# Referencias
